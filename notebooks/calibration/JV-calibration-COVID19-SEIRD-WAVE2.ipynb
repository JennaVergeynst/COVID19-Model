{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "*Original code by Ryan S. McGee. Modified by T.W. Alleman in consultation with the BIOMATH research unit headed by prof. Ingmar Nopens.*\n",
    "\n",
    "Copyright (c) 2020 by T.W. Alleman, BIOMATH, Ghent University. All Rights Reserved.\n",
    "\n",
    "This notebook accompanies our preprint: \"*A deterministic, age-stratified, extended SEIRD model for assessing the effect of non-pharmaceutical interventions on SARS-CoV-2 spread in Belgium*\"(https://doi.org/10.1101/2020.07.17.20156034)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T09:38:19.664518Z",
     "start_time": "2020-12-04T09:38:14.559577Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import corner\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import scipy\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib\n",
    "import math\n",
    "import xarray as xr\n",
    "import emcee\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "from covid19model.optimization import objective_fcns,pso\n",
    "from covid19model.models import models\n",
    "from covid19model.models.utils import draw_sample_COVID19_SEIRD_google\n",
    "from covid19model.models.time_dependant_parameter_fncs import google_lockdown, ramp_fun, contact_matrix\n",
    "from covid19model.data import google\n",
    "from covid19model.data import sciensano\n",
    "from covid19model.data import model_parameters\n",
    "from covid19model.visualization.output import population_status, infected, _apply_tick_locator \n",
    "from covid19model.visualization.optimization import plot_fit, traceplot\n",
    "\n",
    "\n",
    "# OPTIONAL: Load the \"autoreload\" extension so that package code can change\n",
    "%load_ext autoreload\n",
    "# OPTIONAL: always reload modules so that as you change code in src, it gets loaded\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T21:00:25.493086Z",
     "start_time": "2020-11-26T21:00:25.160819Z"
    }
   },
   "outputs": [],
   "source": [
    "initN, Nc_home, Nc_work, Nc_schools, Nc_transport, Nc_leisure, Nc_others, Nc_total = model_parameters.get_interaction_matrices(dataset='willem_2012')\n",
    "levels = initN.size\n",
    "Nc_all = {'total': Nc_total, 'home':Nc_home, 'work': Nc_work, 'schools': Nc_schools, 'transport': Nc_transport, 'leisure': Nc_leisure, 'others': Nc_others}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T07:03:26.558385Z",
     "start_time": "2020-11-24T07:03:26.336972Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(Nc_schools, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T10:05:42.756992Z",
     "start_time": "2020-11-23T10:05:42.541422Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(Nc_leisure, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T10:05:42.756992Z",
     "start_time": "2020-11-23T10:05:42.541422Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(Nc_others, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T21:00:36.238273Z",
     "start_time": "2020-11-26T21:00:36.116201Z"
    }
   },
   "outputs": [],
   "source": [
    "df_sciensano = sciensano.get_sciensano_COVID19_data(update=False)\n",
    "df_sciensano.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T21:00:38.335620Z",
     "start_time": "2020-11-26T21:00:38.266383Z"
    }
   },
   "outputs": [],
   "source": [
    "df_google = google.get_google_mobility_data(update=False, plot=False)\n",
    "df_google.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def switch_beta(t,param,samples_dict):\n",
    "#     if t < pd.to_datetime('2020-05-04'):\n",
    "#         return np.random.choice(samples_dict['beta'],1,replace=False)\n",
    "#     elif pd.to_datetime('2020-05-04') < t <= pd.to_datetime('2020-09-01'):\n",
    "#         return np.random.choice(samples_dict['beta_summer'],1,replace=False)\n",
    "#     else:\n",
    "#         return np.random.choice(samples_dict['beta'],1,replace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wave 2: September 2020 - present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T21:00:41.654814Z",
     "start_time": "2020-11-26T21:00:41.616395Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('../../data/interim/model_parameters/COVID19_SEIRD/calibrations/national/google/initial_states_2020-09-01.json', 'r') as fp:\n",
    "    initial_states = json.load(fp)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T21:00:48.181426Z",
     "start_time": "2020-11-26T21:00:48.143605Z"
    }
   },
   "outputs": [],
   "source": [
    "# Start of data collection\n",
    "start_data = '2020-09-01'\n",
    "# Start data of recalibration ramp\n",
    "start_calibration = '2020-09-01'\n",
    "# Last datapoint used to recalibrate the ramp\n",
    "end_calibration = '2020-11-23'\n",
    "# Path where figures should be stored\n",
    "fig_path = '../../results/calibrations/COVID19_SEIRD/national/'\n",
    "# Path where MCMC samples should be saved\n",
    "samples_path = '../../data/interim/model_parameters/COVID19_SEIRD/calibrations/national/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 prevention parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T21:00:53.352546Z",
     "start_time": "2020-11-26T21:00:53.315298Z"
    }
   },
   "outputs": [],
   "source": [
    "# Spatial unit: Belgium\n",
    "spatial_unit = 'BE_6_prev_thin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T21:00:57.105738Z",
     "start_time": "2020-11-26T21:00:57.050675Z"
    }
   },
   "outputs": [],
   "source": [
    "def contact_matrix(t, df_google, Nc_all, prev_home=1, prev_schools=1, prev_work=1, prev_transport=1, prev_leisure=1, prev_others=1, school=None, work=None, transport=None, leisure=None, others=None):\n",
    "    \"\"\"\n",
    "    t : timestamp\n",
    "        current date\n",
    "    Nc_all : dictionnary\n",
    "        contact matrices for home, schools, work, transport, leisure and others\n",
    "    prev_... : float [0,1]\n",
    "        prevention parameter to estimate\n",
    "    school, work, transport, leisure, others : float [0,1]\n",
    "        level of opening of these sectors\n",
    "        if None, it is calculated from google mobility data\n",
    "        only school cannot be None!\n",
    "    \"\"\"\n",
    "    \n",
    "    if t < pd.Timestamp('2020-03-15'):\n",
    "        CM = Nc_all['total']\n",
    "    else:\n",
    "        \n",
    "        if school is None:\n",
    "            raise ValueError(\n",
    "            \"Please indicate to which extend schools are open\")\n",
    "        \n",
    "        if pd.Timestamp('2020-03-15') < t <= df_google.index[-1]:\n",
    "            #take t.date() because t can be more than a date! (e.g. when tau_days is added)\n",
    "            row = -df_google[df_google.index == pd.Timestamp(t.date())]/100 \n",
    "        else:\n",
    "            row = -df_google.iloc[[-1],:]/100\n",
    "\n",
    "        if work is None:\n",
    "            work=(1-row['work'].values)[0]\n",
    "        if transport is None:\n",
    "            transport=(1-row['transport'].values)[0]\n",
    "        if leisure is None:\n",
    "            leisure=(1-row['retail_recreation'].values)[0]\n",
    "        if others is None:\n",
    "            others=(1-row['grocery'].values)[0]\n",
    "\n",
    "        CM = (prev_home*(1/2.3)*Nc_all['home'] + \n",
    "              prev_schools*school*Nc_all['schools'] + \n",
    "              prev_work*work*Nc_all['work'] + \n",
    "              prev_transport*transport*Nc_all['transport'] + \n",
    "              prev_leisure*leisure*Nc_all['leisure'] + \n",
    "              prev_others*others*Nc_all['others']) \n",
    "\n",
    "\n",
    "    return CM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T21:00:58.301272Z",
     "start_time": "2020-11-26T21:00:58.250345Z"
    }
   },
   "outputs": [],
   "source": [
    "def wave2_policies(t,param,df_google, Nc_all, l , tau, \n",
    "                   prev_schools, prev_work, prev_transport, prev_leisure, prev_others, prev_home):\n",
    "    \n",
    "    # Convert tau and l to dates\n",
    "    tau_days = pd.Timedelta(tau, unit='D')\n",
    "    l_days = pd.Timedelta(l, unit='D')\n",
    "\n",
    "    # Define additional dates where intensity or school policy changes\n",
    "    t1 = pd.Timestamp('2020-03-15') # start of lockdown\n",
    "    t2 = pd.Timestamp('2020-05-15') # gradual re-opening of schools (assume 50% of nominal scenario)\n",
    "    t3 = pd.Timestamp('2020-07-01') # start of summer: COVID-urgency very low\n",
    "    t4 = pd.Timestamp('2020-08-01')\n",
    "    t5 = pd.Timestamp('2020-09-01') # september: lockdown relaxation narrative in newspapers reduces sense of urgency\n",
    "    t6 = pd.Timestamp('2020-10-19') # lockdown\n",
    "    t7 = pd.Timestamp('2020-11-16') # schools re-open\n",
    "    t8 = pd.Timestamp('2020-12-18') # schools close\n",
    "    t9 = pd.Timestamp('2021-01-04') # schools re-open\n",
    "\n",
    "    if t5 < t <= t6 + tau_days:\n",
    "        return contact_matrix(t, df_google, Nc_all, school=1)\n",
    "    elif t6 + tau_days < t <= t6 + tau_days + l_days:\n",
    "        policy_old = contact_matrix(t, df_google, Nc_all, school=1)\n",
    "        policy_new = contact_matrix(t, df_google, Nc_all, prev_home, prev_schools, prev_work, prev_transport, \n",
    "                                    prev_leisure, prev_others, school=0)\n",
    "        return ramp_fun(policy_old, policy_new, t, tau_days, l, t6)\n",
    "    elif t6 + tau_days + l_days < t <= t7:\n",
    "        return contact_matrix(t, df_google, Nc_all, prev_home, prev_schools, prev_work, prev_transport, \n",
    "                              prev_leisure, prev_others, school=0)\n",
    "    elif t7 < t <= t8:\n",
    "        return contact_matrix(t, df_google, Nc_all, prev_home, prev_schools, prev_work, prev_transport, \n",
    "                              prev_leisure, prev_others, school=1)\n",
    "    elif t8 < t <= t9:\n",
    "        return contact_matrix(t, df_google, Nc_all, prev_home, prev_schools, prev_work, prev_transport, \n",
    "                              prev_leisure, prev_others, school=0)\n",
    "    else:\n",
    "        return contact_matrix(t, df_google, Nc_all, prev_home, prev_schools, prev_work, prev_transport, \n",
    "                              prev_leisure, prev_others, school=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T21:01:00.660783Z",
     "start_time": "2020-11-26T21:01:00.305872Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the model parameters using `get_COVID19_SEIRD_parameters()`.\n",
    "params = model_parameters.get_COVID19_SEIRD_parameters()\n",
    "\n",
    "params.update({'df_google': df_google,\n",
    "              'Nc_all' : Nc_all,\n",
    "               'l' : 5,\n",
    "               'tau' : 5,\n",
    "               'prev_schools': 0.5,\n",
    "               'prev_work': 0.5,\n",
    "               'prev_transport': 0.5,\n",
    "               'prev_leisure': 0.5,\n",
    "               'prev_others': 0.5,\n",
    "               'prev_home' : 0.5\n",
    "              })\n",
    "\n",
    "# Initialize the model\n",
    "model = models.COVID19_SEIRD(initial_states, params, time_dependent_parameters={'Nc': wave2_policies})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup=0\n",
    "maxiter = 100\n",
    "popsize = 100\n",
    "processes = 32 # voor eraser!!\n",
    "steps_mcmc = 3000#3000\n",
    "discard = 1000\n",
    "\n",
    "# define dataset\n",
    "data=[df_sciensano['H_in'][start_calibration:end_calibration]]\n",
    "states = [[\"H_in\"]]\n",
    "\n",
    "####################################################\n",
    "####### CALIBRATING BETA AND COMPLIANCE RAMP #######\n",
    "####################################################\n",
    "\n",
    "print('------------------------------------')\n",
    "print('CALIBRATING BETA AND COMPLIANCE RAMP')\n",
    "print('------------------------------------\\n')\n",
    "print('Using data from '+start_calibration+' until '+end_calibration+'\\n')\n",
    "print('1) Particle swarm optimization\\n')\n",
    "\n",
    "# set PSO optimisation settings\n",
    "parNames = ['sigma_data','beta','l','tau',\n",
    "            'prev_schools', 'prev_work', 'prev_transport', 'prev_leisure', 'prev_others', 'prev_home']\n",
    "bounds=((1,2000),(0.010,0.060),(0.1,20),(0.1,20),\n",
    "        (0,1),(0,1),(0,1),(0,1),(0,1),(0,1))\n",
    "\n",
    "# run PSO optimisation\n",
    "theta = pso.fit_pso(model,data,parNames,states,bounds,maxiter=maxiter,popsize=popsize,\n",
    "                    start_date=start_calibration,warmup=warmup, processes=processes) ## PROCESSES=1 to debug!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-26T21:01:07.421Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# run MCMC sampler\n",
    "print('\\n2) Markov-Chain Monte-Carlo sampling\\n')\n",
    "parNames_mcmc = parNames\n",
    "bounds_mcmc=((1,2000),(0.020,0.060),(0.001,20),(0.001,20),\n",
    "             (0,1),(0,1),(0,1),(0,1),(0,1),(0,1))\n",
    "\n",
    "ndim = len(theta)\n",
    "nwalkers = ndim*2\n",
    "perturbations = ([1]+(ndim-1)*[1e-3]) * np.random.randn(nwalkers, ndim)\n",
    "pos = theta + perturbations\n",
    "\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, objective_fcns.log_probability,\n",
    "                    args=(model, bounds_mcmc, data, states, parNames_mcmc, None, start_calibration, warmup))\n",
    "sampler.run_mcmc(pos, steps_mcmc, progress=True)\n",
    "\n",
    "thin = 0\n",
    "try:\n",
    "    autocorr = sampler.get_autocorr_time()\n",
    "    thin = int(0.5 * np.min(autocorr))\n",
    "except:\n",
    "    print('Warning: The chain is shorter than 50 times the integrated autocorrelation time for 4 parameter(s).\\nUse this estimate with caution and run a longer chain!')\n",
    "    sampler.run_mcmc(initial_state=None, nsteps=steps_mcmc, progress=True)\n",
    "from covid19model.optimization.run_optimization import checkplots\n",
    "checkplots(sampler, discard, thin, fig_path, spatial_unit, figname='BETA_RAMP_GOOGLE_WAVE2', \n",
    "           labels=['$\\sigma_{data}$','$\\\\beta$','l','$\\\\tau$',\n",
    "                   'prev_schools', 'prev_work', 'prev_transport', 'prev_leisure', 'prev_others', 'prev_home'])\n",
    "\n",
    "#############################################\n",
    "####### Output to dictionary ################\n",
    "#############################################\n",
    "\n",
    "flat_samples = sampler.get_chain(discard=discard,thin=thin,flat=True)\n",
    "\n",
    "samples_dict_wave2 = {}\n",
    "for count,name in enumerate(parNames_mcmc):\n",
    "    samples_dict_wave2[name] = flat_samples[:,count].tolist()\n",
    "\n",
    "samples_dict_wave2.update({\n",
    "    'theta_pso' : list(theta_pso),\n",
    "    'warmup' : warmup,\n",
    "    'calibration_data' : states[0][0],\n",
    "    'start_date' : start_calibration,\n",
    "    'end_date' : end_calibration,\n",
    "    'maxiter' : maxiter,\n",
    "    'popsize': popsize,\n",
    "    'steps_mcmc': steps_mcmc,\n",
    "    'discard' : discard,\n",
    "})\n",
    "\n",
    "with open(samples_path+str(spatial_unit)+'_'+str(datetime.date.today())+'_WAVE2_GOOGLE.json', 'w') as fp:\n",
    "    json.dump(samples_dict_wave2, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    sampler.get_autocorr_time()\n",
    "except AttributeError:\n",
    "    # Run MCMC\n",
    "    #-------------------------------------------\n",
    "    # Initialize the sampler\n",
    "    sampler = emcee.EnsembleSampler(nwalkers, ndim, log_probability, args = (t_vec, obs_ID))\n",
    "    max_n = 10000\n",
    "\n",
    "    # We'll track how the average autocorrelation time estimate changes\n",
    "    index = 0\n",
    "    autocorr = np.empty(max_n//100)\n",
    "\n",
    "    # This will be useful to testing convergence\n",
    "    old_tau = np.inf\n",
    "\n",
    "    # Now we'll sample for up to max_n steps\n",
    "    for sample in sampler.sample(theta_0, iterations=max_n, progress=True):\n",
    "        # Only check convergence every `step_autocorr` steps\n",
    "        if sampler.iteration % step_autocorr:\n",
    "            continue\n",
    "\n",
    "        # Compute the autocorrelation time so far\n",
    "        # Using tol=0 means that we'll always get an estimate even\n",
    "        # if it isn't trustworthy\n",
    "        tau = sampler.get_autocorr_time(tol=0)\n",
    "        autocorr[index] = np.mean(tau)\n",
    "        index += 1\n",
    "\n",
    "        # Check convergence\n",
    "        converged = np.all(tau * step_autocorr < sampler.iteration) # condition 1: chain is longer than `step_autocorr` times the autocorrelation\n",
    "        converged &= np.all(np.abs(old_tau - tau) / tau < 0.01) # condition 2 : autocorrelation estimate has converged\n",
    "        if converged:\n",
    "            break\n",
    "        old_tau = tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checken waar stopcriterium zit\n",
    "chains = sampler.get_chain()\n",
    "step_autocorr = 100\n",
    "tau_vect = np.empty((len(chains)//100-1,ndim))\n",
    "index = 0\n",
    "for i in range(step_autocorr, len(chains), step_autocorr):\n",
    "    tau_vect[index] = emcee.autocorr.integrated_time(chains[:i], tol = 0)\n",
    "    index += 1\n",
    "n = 100 * np.arange(1, index + 1)\n",
    "plt.plot(n, n / 100.0, \"--k\")\n",
    "plt.plot(n, tau_vect)\n",
    "plt.xlim(0, n.max())\n",
    "plt.xlabel(\"number of steps\")\n",
    "plt.ylabel(r\"$\\hat{\\tau}$\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T08:53:36.579871Z",
     "start_time": "2020-11-20T08:53:35.937765Z"
    }
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "plt.hist(samples_dict_wave2['prev_schools'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T08:58:17.750235Z",
     "start_time": "2020-11-20T08:56:55.942479Z"
    }
   },
   "outputs": [],
   "source": [
    "end_sim = '2021-01-01'\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(10,4))\n",
    "for i in range(100):\n",
    "    # Sampling\n",
    "    idx, model.parameters['beta'] = random.choice(list(enumerate(samples_dict_wave2['beta'])))\n",
    "    model.parameters['l'] = samples_dict_wave2['l'][idx] \n",
    "    model.parameters['tau'] = samples_dict_wave2['tau'][idx]    \n",
    "    model.parameters['prev_schools'] = samples_dict_wave2['prev_schools'][idx]    \n",
    "    model.parameters['prev_work'] = samples_dict_wave2['prev_work'][idx]     \n",
    "    model.parameters['prev_transport'] = samples_dict_wave2['prev_transport'][idx]    \n",
    "    model.parameters['prev_leisure'] = samples_dict_wave2['prev_leisure'][idx]     \n",
    "    model.parameters['prev_others'] = samples_dict_wave2['prev_others'][idx]      \n",
    "\n",
    "    # Simulate\n",
    "    y_model = model.sim(end_sim,start_date=start_calibration,warmup=0)\n",
    "    # Plot\n",
    "    ax.plot(y_model['time'],y_model[\"H_in\"].sum(dim=\"Nc\"),color='blue',alpha=0.05)\n",
    "\n",
    "ax.scatter(df_sciensano[start_calibration:end_calibration].index,df_sciensano['H_in'][start_calibration:end_calibration],color='black',alpha=0.6,linestyle='None',facecolors='none')\n",
    "ax = _apply_tick_locator(ax)\n",
    "ax.set_xlim('2020-09-01',end_sim)\n",
    "fig.savefig(fig_path+'others/FIT_WAVE2_GOOGLE_'+spatial_unit+'_'+str(datetime.date.today())+'.pdf', dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 prevention parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T12:48:25.263384Z",
     "start_time": "2020-11-23T12:48:25.078860Z"
    }
   },
   "outputs": [],
   "source": [
    "# Spatial unit: Belgium\n",
    "spatial_unit = 'BE_4_prev_full'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T10:16:14.440906Z",
     "start_time": "2020-11-23T10:16:14.393073Z"
    }
   },
   "outputs": [],
   "source": [
    "def contact_matrix(t, df_google, Nc_all, prev_home=1, prev_schools=1, prev_work=1, prev_rest=1, school=None, work=None, transport=None, leisure=None, others=None):\n",
    "    \"\"\"\n",
    "    t : timestamp\n",
    "        current date\n",
    "    Nc_all : dictionnary\n",
    "        contact matrices for home, schools, work, transport, leisure and others\n",
    "    prev_... : float [0,1]\n",
    "        prevention parameter to estimate (rest = transport, leisure, others)\n",
    "    school, work, transport, leisure, others : float [0,1]\n",
    "        level of opening of these sectors\n",
    "        if None, it is calculated from google mobility data\n",
    "        only school cannot be None!\n",
    "    \"\"\"\n",
    "    \n",
    "    if t < pd.Timestamp('2020-03-15'):\n",
    "        CM = Nc_all['total']\n",
    "    else:\n",
    "        \n",
    "        if school is None:\n",
    "            raise ValueError(\n",
    "            \"Please indicate to which extend schools are open\")\n",
    "        \n",
    "        if pd.Timestamp('2020-03-15') < t <= df_google.index[-1]:\n",
    "            #take t.date() because t can be more than a date! (e.g. when tau_days is added)\n",
    "            row = -df_google[df_google.index == pd.Timestamp(t.date())]/100 \n",
    "        else:\n",
    "            row = -df_google.iloc[[-1],:]/100\n",
    "\n",
    "        if work is None:\n",
    "            work=(1-row['work'].values)[0]\n",
    "        if transport is None:\n",
    "            transport=(1-row['transport'].values)[0]\n",
    "        if leisure is None:\n",
    "            leisure=(1-row['retail_recreation'].values)[0]\n",
    "        if others is None:\n",
    "            others=(1-row['grocery'].values)[0]\n",
    "\n",
    "        CM = (prev_home*(1/2.3)*Nc_all['home'] + \n",
    "              prev_schools*school*Nc_all['schools'] + \n",
    "              prev_work*work*Nc_all['work'] + \n",
    "              prev_rest*transport*Nc_all['transport'] + \n",
    "              prev_rest*leisure*Nc_all['leisure'] + \n",
    "              prev_rest*others*Nc_all['others']) \n",
    "\n",
    "\n",
    "    return CM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T10:16:14.529726Z",
     "start_time": "2020-11-23T10:16:14.480748Z"
    }
   },
   "outputs": [],
   "source": [
    "def wave2_policies(t,param,df_google, Nc_all, l , tau, \n",
    "                   prev_schools, prev_work, prev_rest, prev_home):\n",
    "    \n",
    "    # Convert tau and l to dates\n",
    "    tau_days = pd.Timedelta(tau, unit='D')\n",
    "    l_days = pd.Timedelta(l, unit='D')\n",
    "\n",
    "    # Define additional dates where intensity or school policy changes\n",
    "    t1 = pd.Timestamp('2020-03-15') # start of lockdown\n",
    "    t2 = pd.Timestamp('2020-05-15') # gradual re-opening of schools (assume 50% of nominal scenario)\n",
    "    t3 = pd.Timestamp('2020-07-01') # start of summer: COVID-urgency very low\n",
    "    t4 = pd.Timestamp('2020-08-01')\n",
    "    t5 = pd.Timestamp('2020-09-01') # september: lockdown relaxation narrative in newspapers reduces sense of urgency\n",
    "    t6 = pd.Timestamp('2020-10-19') # lockdown\n",
    "    t7 = pd.Timestamp('2020-11-16') # schools re-open\n",
    "    t8 = pd.Timestamp('2020-12-18') # schools close\n",
    "    t9 = pd.Timestamp('2021-01-04') # schools re-open\n",
    "\n",
    "    if t5 < t <= t6 + tau_days:\n",
    "        return contact_matrix(t, df_google, Nc_all, school=1)\n",
    "    elif t6 + tau_days < t <= t6 + tau_days + l_days:\n",
    "        policy_old = contact_matrix(t, df_google, Nc_all, school=1)\n",
    "        policy_new = contact_matrix(t, df_google, Nc_all, prev_home, prev_schools, prev_work, prev_rest, \n",
    "                                    school=0)\n",
    "        return ramp_fun(policy_old, policy_new, t, tau_days, l, t6)\n",
    "    elif t6 + tau_days + l_days < t <= t7:\n",
    "        return contact_matrix(t, df_google, Nc_all, prev_home, prev_schools, prev_work, prev_rest, \n",
    "                              school=0)\n",
    "    elif t7 < t <= t8:\n",
    "        return contact_matrix(t, df_google, Nc_all, prev_home, prev_schools, prev_work, prev_rest, \n",
    "                              school=1)\n",
    "    elif t8 < t <= t9:\n",
    "        return contact_matrix(t, df_google, Nc_all, prev_home, prev_schools, prev_work, prev_rest, \n",
    "                              school=0)\n",
    "    else:\n",
    "        return contact_matrix(t, df_google, Nc_all, prev_home, prev_schools, prev_work, prev_rest, \n",
    "                              school=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T10:16:16.383637Z",
     "start_time": "2020-11-23T10:16:16.047364Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the model parameters using `get_COVID19_SEIRD_parameters()`.\n",
    "params = model_parameters.get_COVID19_SEIRD_parameters()\n",
    "\n",
    "params.update({'df_google': df_google,\n",
    "              'Nc_all' : Nc_all,\n",
    "               'l' : 5,\n",
    "               'tau' : 5,\n",
    "               'prev_schools': 0.5,\n",
    "               'prev_work': 0.5,\n",
    "               'prev_rest': 0.5,\n",
    "               'prev_home' : 0.5\n",
    "              })\n",
    "\n",
    "# Initialize the model\n",
    "model = models.COVID19_SEIRD(initial_states, params, time_dependent_parameters={'Nc': wave2_policies})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T12:48:55.228071Z",
     "start_time": "2020-11-23T12:48:55.185588Z"
    }
   },
   "outputs": [],
   "source": [
    "warmup=0\n",
    "maxiter = 100\n",
    "popsize = 100\n",
    "processes = 32 # voor eraser!!\n",
    "steps_mcmc = 3000#3000\n",
    "discard = 1000#1000\n",
    "\n",
    "# define dataset\n",
    "data=[df_sciensano['H_in'][start_calibration:end_calibration]]\n",
    "states = [[\"H_in\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T10:23:38.851239Z",
     "start_time": "2020-11-23T10:16:17.035602Z"
    }
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "####### CALIBRATING BETA AND COMPLIANCE RAMP #######\n",
    "####################################################\n",
    "\n",
    "print('------------------------------------')\n",
    "print('CALIBRATING BETA AND COMPLIANCE RAMP')\n",
    "print('------------------------------------\\n')\n",
    "print('Using data from '+start_calibration+' until '+end_calibration+'\\n')\n",
    "print('1) Particle swarm optimization\\n')\n",
    "\n",
    "# set PSO optimisation settings\n",
    "parNames = ['sigma_data','beta','l','tau',\n",
    "            'prev_schools', 'prev_work', 'prev_rest', 'prev_home']\n",
    "bounds=((1,2000),(0.010,0.060),(0.1,20),(0.1,20),\n",
    "        (0,1),(0,1),(0,1),(0,1))\n",
    "\n",
    "# run PSO optimisation\n",
    "theta = pso.fit_pso(model,data,parNames,states,bounds,maxiter=maxiter,popsize=popsize,\n",
    "                    start_date=start_calibration,warmup=warmup, processes=processes) ## PROCESSES=1 to debug!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T17:51:30.738776Z",
     "start_time": "2020-11-23T12:49:04.013095Z"
    }
   },
   "outputs": [],
   "source": [
    "# run MCMC sampler\n",
    "print('\\n2) Markov-Chain Monte-Carlo sampling\\n')\n",
    "parNames_mcmc = parNames\n",
    "bounds_mcmc=((1,2000),(0.020,0.060),(0.001,20),(0.001,20),\n",
    "             (0,1),(0,1),(0,1),(0,1))\n",
    "\n",
    "ndim = len(theta)\n",
    "nwalkers = ndim*2\n",
    "perturbations = ([1]+(ndim-1)*[1e-3]) * np.random.randn(nwalkers, ndim)\n",
    "pos = theta + perturbations\n",
    "\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, objective_fcns.log_probability,\n",
    "                    args=(model, bounds_mcmc, data, states, parNames_mcmc, None, start_calibration, warmup))\n",
    "sampler.run_mcmc(pos, steps_mcmc, progress=True)\n",
    "\n",
    "thin = 0\n",
    "try:\n",
    "    autocorr = sampler.get_autocorr_time()\n",
    "    thin = int(0.5 * np.min(autocorr))\n",
    "except:\n",
    "    print('Warning: The chain is shorter than 50 times the integrated autocorrelation time for 4 parameter(s).\\nUse this estimate with caution and run a longer chain!')\n",
    "from covid19model.optimization.run_optimization import checkplots\n",
    "checkplots(sampler, discard, thin, fig_path, spatial_unit, figname='BETA_RAMP_GOOGLE_WAVE2', \n",
    "           labels=['$\\sigma_{data}$','$\\\\beta$','l','$\\\\tau$',\n",
    "                   'prev_schools', 'prev_work', 'prev_rest', 'prev_home'])\n",
    "\n",
    "#############################################\n",
    "####### Output to dictionary ################\n",
    "#############################################\n",
    "\n",
    "flat_samples = sampler.get_chain(discard=discard,thin=thin,flat=True)\n",
    "\n",
    "samples_dict_wave2 = {}\n",
    "for count,name in enumerate(parNames_mcmc):\n",
    "    samples_dict_wave2[name] = flat_samples[:,count].tolist()\n",
    "\n",
    "samples_dict_wave2.update({\n",
    "    'theta_pso' : list(theta_pso),\n",
    "    'warmup' : warmup,\n",
    "    'calibration_data' : states[0][0],\n",
    "    'start_date' : start_calibration,\n",
    "    'end_date' : end_calibration,\n",
    "    'maxiter' : maxiter,\n",
    "    'popsize': popsize,\n",
    "    'steps_mcmc': steps_mcmc,\n",
    "    'discard' : discard,\n",
    "})\n",
    "\n",
    "with open(samples_path+str(spatial_unit)+'_'+str(datetime.date.today())+'_WAVE2_GOOGLE.json', 'w') as fp:\n",
    "    json.dump(samples_dict_wave2, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T06:59:17.840420Z",
     "start_time": "2020-11-24T06:59:17.285182Z"
    }
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "plt.hist(samples_dict_wave2['prev_rest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T07:00:58.648567Z",
     "start_time": "2020-11-24T06:59:37.643843Z"
    }
   },
   "outputs": [],
   "source": [
    "end_sim = '2021-01-01'\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(10,4))\n",
    "for i in range(100):\n",
    "    # Sampling\n",
    "    idx, model.parameters['beta'] = random.choice(list(enumerate(samples_dict_wave2['beta'])))\n",
    "    model.parameters['l'] = samples_dict_wave2['l'][idx] \n",
    "    model.parameters['tau'] = samples_dict_wave2['tau'][idx]    \n",
    "    model.parameters['prev_schools'] = samples_dict_wave2['prev_schools'][idx]    \n",
    "    model.parameters['prev_work'] = samples_dict_wave2['prev_work'][idx]       \n",
    "    model.parameters['prev_rest'] = samples_dict_wave2['prev_rest'][idx]      \n",
    "\n",
    "    # Simulate\n",
    "    y_model = model.sim(end_sim,start_date=start_calibration,warmup=0)\n",
    "    # Plot\n",
    "    ax.plot(y_model['time'],y_model[\"H_in\"].sum(dim=\"Nc\"),color='blue',alpha=0.05)\n",
    "\n",
    "ax.scatter(df_sciensano[start_calibration:end_calibration].index,df_sciensano['H_in'][start_calibration:end_calibration],color='black',alpha=0.6,linestyle='None',facecolors='none')\n",
    "ax = _apply_tick_locator(ax)\n",
    "ax.set_xlim('2020-09-01',end_sim)\n",
    "fig.savefig(fig_path+'others/FIT_WAVE2_GOOGLE_'+spatial_unit+'_'+str(datetime.date.today())+'.pdf', dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "170px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
